{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPpbsNq5CBTj6yONqUlH13M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pickle\n","import shap\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import RobustScaler\n","\n","# 1. Load the pickled Random Forest model\n","with open('path_to_your_model.pkl', 'rb') as f:\n","    rf_model = pickle.load(f)\n","\n","# 2. Prepare your test data (you'll need the same features used during training)\n","# If you have a separate test dataset:\n","test_data = pd.read_csv('path_to_test_data.csv')  # Adjust with your actual data source\n","\n","# If you need to preprocess the test data similar to your training:\n","# Make sure to use the same preprocessing steps as in your training\n","X_test = test_data.drop(columns=['org_name', 'ab_name', 'susceptible_flag', 'charttime'])\n","y_test = test_data['susceptible_flag']  # Target variable if available\n","\n","# Apply scaling if it was used in training (use the same scaler)\n","num_cols = X_test.select_dtypes(include=['number']).columns\n","scaler = RobustScaler()  # Ideally, load the same scaler used during training\n","X_test[num_cols] = scaler.fit_transform(X_test[num_cols])\n","\n","# 3. Create a SHAP explainer for the model\n","explainer = shap.TreeExplainer(rf_model)\n","\n","# 4. Calculate SHAP values for the test set\n","shap_values = explainer.shap_values(X_test)\n","\n","# 5. Handle different SHAP value structures\n","# Check the structure of SHAP values\n","print(f\"SHAP values shape/type: {type(shap_values)}\")\n","if isinstance(shap_values, list):\n","    print(f\"List length: {len(shap_values)}\")\n","    for i, sv in enumerate(shap_values):\n","        print(f\"Class {i} shape: {sv.shape}\")\n","elif isinstance(shap_values, np.ndarray):\n","    print(f\"Array shape: {shap_values.shape}\")\n","\n","# 6. Extract the appropriate SHAP values based on structure\n","# For binary classification (common case):\n","if isinstance(shap_values, list) and len(shap_values) == 2:\n","    # Use class 1 (positive class) for binary classification\n","    shap_values_class1 = shap_values[1]\n","    feature_importance = np.abs(shap_values_class1).mean(axis=0)\n","elif isinstance(shap_values, np.ndarray) and len(shap_values.shape) == 3:\n","    # For 3D array structure [samples, features, classes]\n","    shap_values_class1 = shap_values[:, :, 1]  # Get values for class 1\n","    feature_importance = np.abs(shap_values_class1).mean(axis=0)\n","else:\n","    # For single class or regression\n","    feature_importance = np.abs(shap_values).mean(axis=0)\n","\n","# 7. Create DataFrame for feature importance\n","feature_names = X_test.columns  # Get feature names from your test data\n","importance_data = [{'Feature': feat, 'SHAP Importance': imp}\n","                  for feat, imp in zip(feature_names, feature_importance)]\n","\n","feature_importance_df = pd.DataFrame(importance_data)\n","feature_importance_df = feature_importance_df.sort_values('SHAP Importance', ascending=False)\n","\n","# 8. Print top important features\n","print(\"\\nTop 20 important features:\")\n","print(feature_importance_df.head(20))\n","\n","# 9. Create a bar plot for feature importance\n","plt.figure(figsize=(12, 8))\n","top_features = feature_importance_df.head(20)\n","plt.barh(top_features['Feature'], top_features['SHAP Importance'])\n","plt.xlabel('Mean |SHAP Value|')\n","plt.title('Top 20 Feature Importance')\n","plt.gca().invert_yaxis()  # Display highest values at the top\n","plt.tight_layout()\n","plt.savefig('feature_importance.png')  # Save the figure\n","plt.show()\n","\n","# 10. Optional: Create SHAP summary plot\n","try:\n","    # Create a smaller sample for visualization if dataset is large\n","    sample_size = min(100, X_test.shape[0])\n","    X_sample = X_test.iloc[:sample_size]\n","\n","    # Get the appropriate SHAP values for the sample\n","    if isinstance(shap_values, list) and len(shap_values) == 2:\n","        sample_shap = shap_values[1][:sample_size]\n","    elif isinstance(shap_values, np.ndarray) and len(shap_values.shape) == 3:\n","        sample_shap = shap_values[:sample_size, :, 1]\n","    else:\n","        sample_shap = shap_values[:sample_size]\n","\n","    # Create a summary plot\n","    plt.figure(figsize=(12, 8))\n","    shap.summary_plot(\n","        sample_shap,\n","        X_sample,\n","        plot_type=\"bar\",\n","        max_display=20,\n","        show=False\n","    )\n","    plt.title(\"SHAP Summary Plot\")\n","    plt.tight_layout()\n","    plt.savefig('shap_summary.png')  # Save the figure\n","    plt.show()\n","\n","    # Optional: Also create a dot summary plot (shows direction of impact)\n","    plt.figure(figsize=(12, 8))\n","    shap.summary_plot(\n","        sample_shap,\n","        X_sample,\n","        max_display=20,\n","        show=False\n","    )\n","    plt.title(\"SHAP Dot Summary Plot\")\n","    plt.tight_layout()\n","    plt.savefig('shap_dot_summary.png')  # Save the figure\n","    plt.show()\n","except Exception as e:\n","    print(f\"Could not create SHAP summary plot: {e}\")"],"metadata":{"id":"-YutgKCIwrrQ"},"execution_count":null,"outputs":[]}]}